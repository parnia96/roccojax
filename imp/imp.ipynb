{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imp",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eaNODE/wimpbo/blob/master/imp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLDW2wVJ8X_6",
        "colab_type": "text"
      },
      "source": [
        "# **IMP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZCfZlN42gfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# matplotlib , numpy(linalg , numeric computation , matrices) , scikit-learn\n",
        "# svm , cnn(pytorch/tensorflow/keras) and opencv to destroy all victim images using orcus\n",
        "\n",
        "\n",
        "# # http://setosa.io/ev/image-kernels/\n",
        "# https://www.hindawi.com/journals/js/2016/8742920/\n",
        "# https://github.com/ArtyZiff35/3D_Reconstruction_From_Stereo_Images\n",
        "# http://mccormickml.com/2014/01/10/stereo-vision-tutorial-part-i/\n",
        "# https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/\n",
        "# http://scipy-lectures.org/advanced/image_processing/\n",
        "# https://github.com/AlexJinlei/Stereo_Vision_Camera\n",
        "# https://github.com/topics/depth-map\n",
        "# https://kushalvyas.github.io/calib.html\n",
        "# https://github.com/topics/depthmap\n",
        "# https://github.com/topics/disparity-map\n",
        "# http://www.aishack.in/tutorials/sift-scale-invariant-feature-transform-introduction/\n",
        "# https://scipython.com/book/chapter-8-scipy/additional-examples/interpolation-of-an-image/\n",
        "# https://youtu.be/-ZrDjwXZGxI\n",
        "# https://www.youtube.com/watch?v=2Q4L3MtdAbY\n",
        "# https://www.youtube.com/playlist?list=PLh6SAYydrIpctChfPFBlopqw-TGjwWf_8\n",
        "# https://www.youtube.com/playlist?list=PLiHa1s-EL3vjr0Z02ihr6Lcu4Q0rnRvjm\n",
        "# https://www.pyimagesearch.com/2016/01/11/opencv-panorama-stitching/\n",
        "# https://opencv-python-tutroals.readthedocs.io\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PvHsMOo8dO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ------------------\n",
        "# CAMERA CALIBRATION\n",
        "# ------------------\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "\n",
        "# %matplotlib inline\n",
        "\n",
        "\n",
        "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
        "objp = np.zeros((6*8,3), np.float32)\n",
        "objp[:,:2] = np.mgrid[0:8, 0:6].T.reshape(-1,2)\n",
        "\n",
        "# Arrays to store object points and image points from all the images.\n",
        "objpoints = [] # 3d points in real world space\n",
        "imgpoints = [] # 2d points in image plane.\n",
        "\n",
        "# Make a list of calibration images\n",
        "images = glob.glob('/gdrive/My Drive/calib/*.jpg')\n",
        "\n",
        "# Step through the list and search for chessboard corners\n",
        "for idx, fname in enumerate(images):\n",
        "    img = cv2.imread(fname)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find the chessboard corners\n",
        "    ret, corners = cv2.findChessboardCorners(gray, (8,6), None)\n",
        "\n",
        "    # If found, add object points, image points\n",
        "    if ret == True:\n",
        "        objpoints.append(objp)\n",
        "        imgpoints.append(corners)\n",
        "\n",
        "        # Draw and display the corners\n",
        "        cv2.drawChessboardCorners(img, (8,6), corners, ret)\n",
        "        #write_name = 'corners_found'+str(idx)+'.jpg'\n",
        "        #cv2.imwrite(write_name, img)\n",
        "#         cv2.imshow('img', img)\n",
        "        plt.imshow(img)\n",
        "        plt.show()\n",
        "        cv2.waitKey(500)\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# Test undistortion on an image\n",
        "img = cv2.imread('/gdrive/My Drive/calib/2.jpg')\n",
        "img_size = (img.shape[1], img.shape[0])\n",
        "\n",
        "# Do camera calibration given object points and image points\n",
        "# return camera matrix, distortion coefficients, rotation and translation vectors etc.\n",
        "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
        "np.savez('/gdrive/My Drive/calib/calib.npz', mtx=mtx, dist=dist, rvecs=rvecs, tvecs=tvecs)\n",
        "\n",
        "dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
        "cv2.imwrite('/gdrive/My Drive/calib/test_undist.jpg',dst)\n",
        "\n",
        "# Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
        "dist_pickle = {}\n",
        "dist_pickle[\"mtx\"] = mtx\n",
        "dist_pickle[\"dist\"] = dist\n",
        "pickle.dump( dist_pickle, open( \"/gdrive/My Drive/calib/wide_dist_pickle.p\", \"wb\" ) )\n",
        "dst = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
        "# Visualize undistortion\n",
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
        "ax1.imshow(img)\n",
        "ax1.set_title('Original Image', fontsize=30)\n",
        "ax2.imshow(dst)\n",
        "ax2.set_title('Undistorted Image', fontsize=30)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so0iuGgM45KI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/env python\n",
        "\n",
        "# ------------------\n",
        "# CAMERA CALIBRATION\n",
        "# ------------------\n",
        "\n",
        "\n",
        "# NOTE: run this on ur local machine!\n",
        "\n",
        "\"\"\"\n",
        "Running\n",
        "cameracalib.py  <folder> <image type> <num rows> <num cols> <cell dimension>\n",
        "like calib.py calib png\n",
        "--h for help\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "import numpy as np\n",
        "import cv2, glob, sys, argparse\n",
        "\n",
        "#---------------------- SET THE PARAMETERS\n",
        "nRows = 9\n",
        "nCols = 6\n",
        "dimension = 25 #- mm\n",
        "\n",
        "workingFolder   = \"/gdrive/My Drive/calib\"\n",
        "imageType       = 'jpg'\n",
        "#------------------------------------------\n",
        "\n",
        "# termination criteria\n",
        "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, dimension, 0.001)\n",
        "\n",
        "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
        "objp = np.zeros((nRows*nCols,3), np.float32)\n",
        "objp[:,:2] = np.mgrid[0:nCols,0:nRows].T.reshape(-1,2)\n",
        "\n",
        "# Arrays to store object points and image points from all the images.\n",
        "objpoints = [] # 3d point in real world space\n",
        "imgpoints = [] # 2d points in image plane.\n",
        "\n",
        "if len(sys.argv) < 6:\n",
        "        print(\"\\n [-] Not enough inputs are provided. Using the default values.\\n\\n\" \\\n",
        "              \" type -h for help\")\n",
        "else:\n",
        "    workingFolder   = sys.argv[1]\n",
        "    imageType       = sys.argv[2]\n",
        "    nRows           = int(sys.argv[3])\n",
        "    nCols           = int(sys.argv[4])\n",
        "    dimension       = float(sys.argv[5])\n",
        "\n",
        "if '-h' in sys.argv or '--h' in sys.argv:\n",
        "    print(\"\\n IMAGE CALIBRATION GIVEN A SET OF IMAGES\")\n",
        "    print(\" call: python calib.py <folder> <image type> <num rows (9)> <num cols (6)> <cell dimension (25)>\")\n",
        "    print(\"\\n The script will look for every image in the provided folder and will show the pattern found.\" \\\n",
        "          \" User can skip the image pressing ESC or accepting the image with RETURN. \" \\\n",
        "          \" At the end the end the following files are created:\" \\\n",
        "          \"  - cameraDistortion.txt\" \\\n",
        "          \"  - cameraMatrix.txt \\n\\n\")\n",
        "\n",
        "    sys.exit()\n",
        "\n",
        "# Find the images files\n",
        "filename    = workingFolder + \"/*.\" + imageType\n",
        "images      = glob.glob(filename)\n",
        "\n",
        "print(\"[+] IMAGES >>> \", len(images))\n",
        "if len(images) < 9:\n",
        "    print(\"[-] Not enough images were found: at least 9 shall be provided!!!\")\n",
        "    sys.exit()\n",
        "\n",
        "\n",
        "\n",
        "else:\n",
        "    nPatternFound = 0\n",
        "    imgNotGood = images[1]\n",
        "\n",
        "    for fname in images:\n",
        "        if 'calibresult' in fname: continue\n",
        "        #-- Read the file and convert in greyscale\n",
        "        img     = cv2.imread(fname)\n",
        "        gray    = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        print(\"[+] Reading image \", fname)\n",
        "\n",
        "        # Find the chess board corners\n",
        "        ret, corners = cv2.findChessboardCorners(gray, (nCols,nRows),None)\n",
        "\n",
        "        # If found, add object points, image points (after refining them)\n",
        "        if ret == True:\n",
        "            print(\"[+] Pattern found! Press ESC to skip or ENTER to accept\")\n",
        "            #--- Sometimes, Harris cornes fails with crappy pictures, so\n",
        "            corners2 = cv2.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)\n",
        "\n",
        "            # Draw and display the corners\n",
        "            cv2.drawChessboardCorners(img, (nCols,nRows), corners2,ret)\n",
        "            cv2.imshow('img',img)\n",
        "            # cv2.waitKey(0)\n",
        "            k = cv2.waitKey(0) & 0xFF\n",
        "            if k == 27: #-- ESC Button\n",
        "                print(\"[+] Image Skipped\")\n",
        "                imgNotGood = fname\n",
        "                continue\n",
        "\n",
        "            print(\"[+] Image accepted\")\n",
        "            nPatternFound = nPatternFound + 1\n",
        "            # print(nPatternFound)\n",
        "            objpoints.append(objp)\n",
        "            imgpoints.append(corners2)\n",
        "\n",
        "            # cv2.waitKey(0)\n",
        "        else:\n",
        "            imgNotGood = fname\n",
        "\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "if (nPatternFound >= 1):\n",
        "    print(\"[+] Found %d good images\" % (nPatternFound))\n",
        "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1],None,None)\n",
        "\n",
        "    # Undistort an image\n",
        "    img = cv2.imread(imgNotGood)\n",
        "    h,  w = img.shape[:2]\n",
        "    print(\"[+] Image to undistort: \", imgNotGood)\n",
        "    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))\n",
        "\n",
        "    # undistort\n",
        "    mapx,mapy = cv2.initUndistortRectifyMap(mtx,dist,None,newcameramtx,(w,h),5)\n",
        "    dst = cv2.remap(img,mapx,mapy,cv2.INTER_LINEAR)\n",
        "\n",
        "    # crop the image\n",
        "    x,y,w,h = roi\n",
        "    dst = dst[y:y+h, x:x+w]\n",
        "    print(\"[+] ROI: \", x, y, w, h)\n",
        "\n",
        "    cv2.imwrite(workingFolder + \"/calibresult.png\",dst)\n",
        "    print(\"[+] Calibrated picture saved as calibresult.png\")\n",
        "    print(\"[+] Calibration Matrix: \")\n",
        "    print(mtx)\n",
        "    print(\"[+] Disortion: \", dist)\n",
        "\n",
        "    #--------- Save result\n",
        "    filename = workingFolder + \"/cameraMatrix.txt\"\n",
        "    np.savetxt(filename, mtx, delimiter=',')\n",
        "    filename = workingFolder + \"/cameraDistortion.txt\"\n",
        "    np.savetxt(filename, dist, delimiter=',')\n",
        "\n",
        "    mean_error = 0\n",
        "    for i in range(len(objpoints)):\n",
        "        imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
        "        error = cv2.norm(imgpoints[i],imgpoints2, cv2.NORM_L2)/len(imgpoints2)\n",
        "        mean_error += error\n",
        "\n",
        "    print(\"[!] total error: \", mean_error/len(objpoints))\n",
        "\n",
        "else:\n",
        "    print(\"[!] In order to calibrate you need at least 9 good pictures... try again\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1ZfHkIc0HU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# ------------------\n",
        "# PANORAMA STICHTING\n",
        "# ------------------\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randrange\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "img_ = cv2.imread('/gdrive/My Drive/pan/r.jpg')\n",
        "img1 = cv2.cvtColor(img_,cv2.COLOR_BGR2GRAY)\n",
        "img = cv2.imread('/gdrive/My Drive/pan/l.jpg')\n",
        "img2 = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "sift = cv2.ORB_create()\n",
        "# find the keypoints and descriptors with SIFT\n",
        "kp1, des1 = sift.detectAndCompute(img1,None)\n",
        "kp2, des2 = sift.detectAndCompute(img2,None)\n",
        "\n",
        "bf = cv2.BFMatcher()\n",
        "matches = bf.knnMatch(des1,des2, k=2)\n",
        "\n",
        "# Apply ratio test\n",
        "good = []\n",
        "for m in matches:\n",
        "  if m[0].distance < 0.8*m[1].distance:\n",
        "    good.append(m)\n",
        "matches = np.asarray(good)\n",
        "\n",
        "if len(matches[:,0]) >= 4:\n",
        "  src = np.float32([ kp1[m.queryIdx].pt for m in matches[:,0] ]).reshape(-1,1,2)\n",
        "  dst = np.float32([ kp2[m.trainIdx].pt for m in matches[:,0] ]).reshape(-1,1,2)\n",
        "  H, masked = cv2.findHomography(src, dst, cv2.RANSAC, 5.0)\n",
        "else:\n",
        "  raise AssertionError('Can’t find enough keypoints.')\n",
        "\n",
        "dst = cv2.warpPerspective(img_,H,(img.shape[1] + img_.shape[1], img.shape[0]))\n",
        "# plt.subplot(122),plt.imshow(dst),plt.title('Warped Image')\n",
        "# plt.show()\n",
        "# plt.figure()\n",
        "dst[0:img.shape[0], 0:img.shape[1]] = img\n",
        "cv2.imwrite('/gdrive/My Drive/pan/output.jpg',dst)\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.imshow(dst)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}